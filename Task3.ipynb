{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openvino"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrdNBEPIB1f7",
        "outputId": "5a9f1bba-8e94-4c5c-c615-e6e13679ad71"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openvino in /usr/local/lib/python3.10/dist-packages (2024.4.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from openvino) (1.26.4)\n",
            "Requirement already satisfied: openvino-telemetry>=2023.2.1 in /usr/local/lib/python3.10/dist-packages (from openvino) (2024.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from openvino) (24.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openvino-dev[onnx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb5hZtx2CP64",
        "outputId": "ff6e5fc7-ec46-4417-dd45-3734c5578149"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openvino-dev[onnx] in /usr/local/lib/python3.10/dist-packages (2024.4.0)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from openvino-dev[onnx]) (0.7.1)\n",
            "Requirement already satisfied: networkx<=3.1.0 in /usr/local/lib/python3.10/dist-packages (from openvino-dev[onnx]) (3.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from openvino-dev[onnx]) (1.26.4)\n",
            "Requirement already satisfied: openvino-telemetry>=2023.2.1 in /usr/local/lib/python3.10/dist-packages (from openvino-dev[onnx]) (2024.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from openvino-dev[onnx]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from openvino-dev[onnx]) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.10/dist-packages (from openvino-dev[onnx]) (2.32.3)\n",
            "Requirement already satisfied: openvino==2024.4.0 in /usr/local/lib/python3.10/dist-packages (from openvino-dev[onnx]) (2024.4.0)\n",
            "Requirement already satisfied: fastjsonschema<2.18,>=2.15.1 in /usr/local/lib/python3.10/dist-packages (from openvino-dev[onnx]) (2.17.1)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.18.1 in /usr/local/lib/python3.10/dist-packages (from openvino-dev[onnx]) (3.20.3)\n",
            "Requirement already satisfied: onnx<=1.16.0,>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from openvino-dev[onnx]) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->openvino-dev[onnx]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->openvino-dev[onnx]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->openvino-dev[onnx]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->openvino-dev[onnx]) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flash-attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne4YM0X6B3IJ",
        "outputId": "43f6b1c5-aa32-49aa-ceb5-9a17b5e3b5ea"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flash-attn in /usr/local/lib/python3.10/dist-packages (2.6.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.4.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrpnZsXDFEU-",
        "outputId": "91dbd212-41ae-4c8f-fc08-0c8959c8d684"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "from openvino.runtime import Core\n",
        "from transformers import AutoProcessor\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import torch\n",
        "import onnx\n",
        "import os\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=torch.jit.TracerWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "aaGusiWrlzfM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Florence-2-base-ft\", torch_dtype=torch_dtype, trust_remote_code=True).to(device)\n",
        "processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-base-ft\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "jxTgSQf8q_Ye"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disable flash attention"
      ],
      "metadata": {
        "id": "WMCIoxEgrXpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def disable_flash_attention(model):\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'use_flash_attention'):\n",
        "            print(f\"Disabling flash attention in {name}\")\n",
        "            module.use_flash_attention = False"
      ],
      "metadata": {
        "id": "qLceA393plPl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle conditional code"
      ],
      "metadata": {
        "id": "cfszfFLGrlII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_conditional_code(model):\n",
        "    for name, module in model.named_modules():\n",
        "        if \"non_traceable\" in name:\n",
        "            print(f\"Handling non-traceable section in {name}\")\n",
        "            pass"
      ],
      "metadata": {
        "id": "IGRSiQpWptBY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disable_flash_attention(model)\n",
        "handle_conditional_code(model)"
      ],
      "metadata": {
        "id": "QvIhWA0spzQi"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating input for text and image"
      ],
      "metadata": {
        "id": "6N4HQ2dJr91O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input_ids = torch.ones(1, 12, dtype=torch.long).to(device)\n",
        "dummy_pixel_values = torch.randn(1, 3, 224, 224).to(device)\n",
        "dummy_decoder_input_ids = torch.ones(1, 12, dtype=torch.long).to(device)\n",
        "dummy_attention_mask = torch.ones_like(dummy_input_ids).to(device)\n",
        "dummy_decoder_attention_mask = torch.ones_like(dummy_decoder_input_ids).to(device)"
      ],
      "metadata": {
        "id": "U-5gsLYYp6Au"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "exporting the model to onnx"
      ],
      "metadata": {
        "id": "cTUfL_67sUvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model_path = \"florence_cpu_model.onnx\"\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    (dummy_input_ids, dummy_pixel_values, dummy_decoder_input_ids, dummy_attention_mask, dummy_decoder_attention_mask),\n",
        "    onnx_model_path,\n",
        "    export_params=True,\n",
        "    opset_version=14,\n",
        "    do_constant_folding=True,\n",
        "    input_names=['input_ids', 'pixel_values', 'decoder_input_ids', 'attention_mask', 'decoder_attention_mask'],\n",
        "    output_names=['output'],\n",
        "    dynamic_axes={\n",
        "        'input_ids': {0: 'batch_size'},\n",
        "        'pixel_values': {0: 'batch_size'},\n",
        "        'decoder_input_ids': {0: 'batch_size'},\n",
        "        'attention_mask': {0: 'batch_size'},\n",
        "        'decoder_attention_mask': {0: 'batch_size'},\n",
        "        'output': {0: 'batch_size'}\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "MQZ6xtpcp-ea"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting onnx to openvino model"
      ],
      "metadata": {
        "id": "nA2HZb1Osfwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"model exported to onxx format at {onnx_model_path}\")\n",
        "os.system(f\"mo --input_model {onnx_model_path} --output_dir ./openvino_model\")\n",
        "print(\"model successfully converted to OpenVino format\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx-Ag0fOqDW7",
        "outputId": "e8aaa6d2-8281-45fd-edf2-01facb9f4306"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model exported to onxx format at florence_cpu_model.onnx\n",
            "model successfully converted to OpenVino format\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Script"
      ],
      "metadata": {
        "id": "QQe9ethLtDyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#decoding method for better output\n",
        "def softmax(x, temperature=1.0):\n",
        "    x = x / temperature\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return e_x / e_x.sum(axis=-1, keepdims=True)\n",
        "\n",
        "def top_k_sampling(probs, k=5, penalty_factor=0.9, penalize_tokens=['<loc_0>']):\n",
        "    batch_size, seq_len, vocab_size = probs.shape\n",
        "    indices = np.argpartition(probs, -k, axis=-1)[:, :, -k:]\n",
        "    selected_indices = np.zeros((batch_size, seq_len), dtype=np.int64)\n",
        "    for i in range(seq_len):\n",
        "        choices = indices[0, i, :]\n",
        "        weighted_probs = probs[0, i, choices] * penalty_factor\n",
        "        for j, choice in enumerate(choices):\n",
        "            token_str = processor.tokenizer.convert_ids_to_tokens([choice])[0]\n",
        "            if token_str in penalize_tokens:\n",
        "                weighted_probs[j] *= 0.1\n",
        "        selected_indices[:, i] = np.random.choice(choices, p=weighted_probs / weighted_probs.sum())\n",
        "    return selected_indices"
      ],
      "metadata": {
        "id": "ZGJujMuXqWBg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the model\n",
        "core = Core()\n",
        "model_path = \"./openvino_model/florence_cpu_model.xml\"\n",
        "compiled_model = core.compile_model(model_path, \"CPU\")\n",
        "processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-base-ft\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "D4nh7cgxqyAB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"model input names and potential shapes\")\n",
        "for input in compiled_model.inputs:\n",
        "    shape = input.get_partial_shape()\n",
        "    print(f\"{input.get_any_name()}: {shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5-CwZtXwCOj",
        "outputId": "f3262d03-7d92-467f-d27c-313926f26737"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model input names and potential shapes\n",
            "input_ids: [?,12]\n",
            "pixel_values: [?,3,224,224]\n",
            "attention_mask: [?,12]\n",
            "decoder_attention_mask: [?,12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = 'https://images.unsplash.com/photo-1501594907352-04cda38ebc29'\n",
        "response = requests.get(image_url)\n",
        "if 'image' in response.headers.get('Content-Type', ''):\n",
        "    real_image = Image.open(BytesIO(response.content))\n",
        "    print(\"Image successfully opened\")\n",
        "else:\n",
        "    raise ValueError(f\"failed to download image or invalid content type: {response.headers['Content-Type']}\")\n",
        "real_image = real_image.resize((224, 224))\n",
        "image_array = np.array(real_image).astype(np.float32)\n",
        "image_array = image_array.transpose(2, 0, 1)\n",
        "image_array = np.expand_dims(image_array, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7JSGUs0tkkR",
        "outputId": "3ba05fb6-405a-4d27-a276-41aa83b94846"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image successfully opened\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = \"What does this image show?\"\n",
        "inputs = processor(text=[text_input], images=real_image, return_tensors=\"np\", padding=False, truncation=False)"
      ],
      "metadata": {
        "id": "jABtEnVcwe0J"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing according to model\n",
        "input_ids = inputs['input_ids']\n",
        "if input_ids.shape[1] > 12:\n",
        "    input_ids = input_ids[:, :12]\n",
        "elif input_ids.shape[1] < 12:\n",
        "    padding_length = 12 - input_ids.shape[1]\n",
        "    input_ids = np.pad(input_ids, ((0, 0), (0, padding_length)), constant_values=processor.tokenizer.pad_token_id)\n",
        "\n",
        "attention_mask = inputs['attention_mask']\n",
        "if attention_mask.shape[1] > 12:\n",
        "    attention_mask = attention_mask[:, :12]\n",
        "elif attention_mask.shape[1] < 12:\n",
        "    padding_length = 12 - attention_mask.shape[1]\n",
        "    attention_mask = np.pad(attention_mask, ((0, 0), (0, padding_length)), constant_values=0)"
      ],
      "metadata": {
        "id": "ZPZKSEYrq6GP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_attention_mask = attention_mask.copy()\n",
        "inputs_dict = {\n",
        "    \"input_ids\": input_ids.astype(np.int64),\n",
        "    \"pixel_values\": image_array.astype(np.float32),\n",
        "    \"attention_mask\": attention_mask.astype(np.int64),\n",
        "    \"decoder_attention_mask\": decoder_attention_mask.astype(np.int64)\n",
        "}"
      ],
      "metadata": {
        "id": "tNuA9uv-q_c6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#running inference and applying deconding method\n",
        "output = compiled_model(inputs_dict)\n",
        "output_data = output['/language_model/Add_output_0']\n",
        "output_probs = softmax(output_data, temperature=0.7)\n",
        "predicted_token_ids = top_k_sampling(output_probs, k=5, penalty_factor=0.9, penalize_tokens=['<loc_0>'])\n",
        "tokens = processor.tokenizer.convert_ids_to_tokens(predicted_token_ids[0].tolist())"
      ],
      "metadata": {
        "id": "wPaIa3AmrJMj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#post-processing\n",
        "cleaned_tokens = []\n",
        "for token in tokens:\n",
        "    if token not in ['<s>', '</s>', '<pad>'] and not (token in cleaned_tokens and token in [',', '.', \"'\"]):\n",
        "        cleaned_tokens.append(token)\n",
        "decoded_output = \" \".join(cleaned_tokens)\n",
        "decoded_output = decoded_output.replace(\" Ä \", \" \").replace(\" '\", \"'\").strip()\n",
        "decoded_output = decoded_output.replace(\" ,\", \",\").replace(\" .\", \".\").replace(\" 's\", \"'s\")\n",
        "print(\"Decoded output:\", decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZcMrP0Ju0vw",
        "outputId": "19061b9a-655b-4d8d-9776-9e92094f4b24"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded output: water  on\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "import onnx\n",
        "import openvino\n",
        "import PIL\n",
        "import numpy as np\n",
        "import requests\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Transformers version: {transformers.__version__}\")\n",
        "print(f\"ONNX version: {onnx.__version__}\")\n",
        "print(f\"OpenVINO version: {openvino.__version__}\")\n",
        "print(f\"Pillow (PIL) version: {PIL.__version__}\")\n",
        "print(f\"Numpy version: {np.__version__}\")\n",
        "print(f\"Requests version: {requests.__version__}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1o6RF2GDjYR",
        "outputId": "0512fe7f-23a6-4ada-c8eb-eb3ebf70dd62"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.4.1+cu121\n",
            "Transformers version: 4.44.2\n",
            "ONNX version: 1.16.0\n",
            "OpenVINO version: 2024.4.0-16579-c3152d32c9c-releases/2024/4\n",
            "Pillow (PIL) version: 10.4.0\n",
            "Numpy version: 1.26.4\n",
            "Requests version: 2.32.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7MMPnQTJRE6h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}